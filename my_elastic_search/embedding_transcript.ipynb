{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data into a DataFrame\n",
    "\n",
    "file_name = \"labeled_transcript_01.csv\"\n",
    "data = pd.read_csv(f\"./data/labeled/{file_name}\")\n",
    "\n",
    "model_name = \"paraphrase-multilingual-mpnet-base-v2\"\n",
    "# model_name = r\"C:\\Users\\ARM\\.cache\\torch\\sentence_transformers\\sentence-transformers_paraphrase-multilingual-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Generate embeddings for your text data\n",
    "embeddings = model.encode(data[\"text\"].tolist(), convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch credentials\n",
    "username = \"elastic\"\n",
    "password = \"changeme\"\n",
    "\n",
    "# Establish connection to Elasticsearch with credentials and timeout\n",
    "es = Elasticsearch(\n",
    "    [\"http://localhost:9200\"],\n",
    "    basic_auth=(username, password),\n",
    "    request_timeout=30  # Timeout set to 30 seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'elasticsearch', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'zOK1mryoTaWg-9ifIohEsg', 'version': {'number': '8.12.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '48a287ab9497e852de30327444b0809e55d46466', 'build_date': '2024-02-19T10:04:32.774273190Z', 'build_snapshot': False, 'lucene_version': '9.9.2', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_id_from_file(file):\n",
    "    match = re.search(r'labeled_transcript_(\\d+)', file)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        return number\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_query_map.csv\n",
      "labeled_transcript_01.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a369ecc7a3492684d67b81926a7d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_02.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50af46d8e92b4d589e0d2ccb1c6a6735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_03.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bbc3b92c6c4253838fb476925f13ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_04.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f255fdabab9846d28abf32d42fb68975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_05.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1e244091a1480b81b697ed4134bf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_06.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6448b767841943bda009d83904af9ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_07.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f778c6625da4ece9da97d4c6543a064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_08.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3818d0df784d3598b2219e8e8753c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_transcript_09.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5120374a5ba448259753491477f43608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_map.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(f\"./data/labeled\"):\n",
    "    print(file)\n",
    "    if \"transcript\" not in file:\n",
    "        continue\n",
    "    filename = f\"./data/labeled/{file}\"\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    \n",
    "    file_id = get_id_from_file(filename)\n",
    "\n",
    "    corpus_embeddings = df[\"text\"]\n",
    "    start_time = df[\"start_time\"]\n",
    "    stop_time = df[\"stop_time\"]\n",
    "    corpus_embeddings = model.encode(\n",
    "        corpus_embeddings, convert_to_tensor=False, show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        doc = {\n",
    "            \"text\": df[\"text\"][i],\n",
    "            \"start_time\": df[\"start_time\"][i],\n",
    "            \"stop_time\": df[\"stop_time\"][i],\n",
    "            \"embedding\": corpus_embeddings[i].tolist()  # Convert numpy array to list\n",
    "        }\n",
    "        # Index document into Elasticsearch\n",
    "        res = es.index(index=f\"transcript_{file_id}\", body=doc)\n",
    "        # print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': ['linear program',\n",
       "  'Assumption of linear program',\n",
       "  'standard form of linear program',\n",
       "  'basic feasible solution',\n",
       "  'direction of unboundedness',\n",
       "  'optimization เอาไปใช้ทำอะไร',\n",
       "  'ประเภทของปัญหา optimization แบบ dynamic กับ static ต่างกันยังไง',\n",
       "  'ทำไม feasible region ของ linear program ถึงเป็น convex set ทั้งหมด',\n",
       "  'จะเปลี่ยน constraints เป็น standard form ยังไง',\n",
       "  'direction of unboundedness หายังไง'],\n",
       " '02': ['homework',\n",
       "  'MLE properties',\n",
       "  'covariance',\n",
       "  'scipy function',\n",
       "  'Confidence interval',\n",
       "  'ทำไมสามารถหา argmax โดยใช้ log ได้',\n",
       "  'สุ่มตัวแปรจาก distribution ที่ไม่เป็นมาตรฐานได้อย่างไร',\n",
       "  'MLE เป็นมุมมองของ Frequentist หรือ Bayesian',\n",
       "  'สิ่งใดทำให้ผลของ bayesian estimate เปลี่ยน',\n",
       "  'MLE จะเท่ากับ MAP เมื่อใด'],\n",
       " '03': ['Reject Region',\n",
       "  'power',\n",
       "  'Central limit theorem',\n",
       "  'Type of error',\n",
       "  'Exercise',\n",
       "  'เราควรตั้ง Null Hypothesis อย่างไร',\n",
       "  \"student's t distribution กับ standard gaussian ต่างกันอย่างไร\",\n",
       "  'เราควรกำหนด sample size อย่างไร',\n",
       "  'P-value หาอย่างไร',\n",
       "  'ปัญหา p-hacking คืออะไร แก้ได้อย่างไร'],\n",
       " '04': ['Fundamental Period',\n",
       "  'Power',\n",
       "  'Shifting',\n",
       "  'Time-Scaling',\n",
       "  'Continuous-Time signal',\n",
       "  'Periodic กับ Aperiodic Signal ต่างกันอย่างไง',\n",
       "  'คุณสมบัติของ Continous signal คืออะไร',\n",
       "  'แสดงวิธีการบวก Periodic signal',\n",
       "  'Power Signal กับ Energy Signal ใช้ต่างกันอย่างไร',\n",
       "  'ขอตัวอย่าง Transformation'],\n",
       " '05': ['sampling function',\n",
       "  'Continous Unit Impulse function',\n",
       "  'transformation discrete',\n",
       "  'Discrete Unit Impulse function',\n",
       "  'สัญญาณ discrete',\n",
       "  'even signal ต่างกับ odd signal อย่างไร',\n",
       "  'คุณสมบัติของ Unit Impulse function มีอะไรบ้าง',\n",
       "  'วิธีหาคาบใน discrete signal',\n",
       "  'ตัวอย่างการคำนวณ Transform discrete ',\n",
       "  'อธิบายสูตรของ Sampling property'],\n",
       " '06': ['sampling theorem',\n",
       "  'aliasing',\n",
       "  'averaging filter',\n",
       "  'low pass filter',\n",
       "  'interpolation',\n",
       "  'filtering คืออะไร',\n",
       "  'averaging filter ใน frequency domain ทำอย่างไร',\n",
       "  'high pass filter คืออะไร',\n",
       "  'ทำไมถึงใช้ practical filter แทน ideal filter',\n",
       "  'จำนวนจุดในmoving average มีผลยังไงกับสัญญาณ'],\n",
       " '07': ['confounder',\n",
       "  'attribution period',\n",
       "  'distribution ใน AB test',\n",
       "  'minimum detectable effect',\n",
       "  'โปรเจค',\n",
       "  'metrics ใน AB test มีอะไรบ้าง',\n",
       "  'attribution period แบบ event based กับ cohort based ต่างกันอย่างไร',\n",
       "  'การแบ่งuserแบบ 50/50 กับ 80/20 ต่างกันยังไง',\n",
       "  'การคำนวณ sample size ทำอย่างไร',\n",
       "  'ข้อจำกัดของ AB test มีอะไรบ้าง'],\n",
       " '08': ['epsilon greedy',\n",
       "  'annealing',\n",
       "  'softmax',\n",
       "  'upper confidence bound',\n",
       "  'reinforcement learning',\n",
       "  'ข้อเสียของ AB testing มีอะไรบ้าง',\n",
       "  'exploraion กับ exploitation ต่างกันยังไง',\n",
       "  'temperature คืออะไร',\n",
       "  'epsilon-greedy, ucb และ softmax ต่างกันอย่างไร',\n",
       "  'ข้อจำกัดของ multiarm bandit เทียบกับ AB test คืออะไร'],\n",
       " '09': ['simplex algorithm',\n",
       "  'ratio test',\n",
       "  'non degenerate',\n",
       "  'Big M',\n",
       "  'Two phase',\n",
       "  'basic solution ต่างจาก basic feasible solution อย่างไร',\n",
       "  'หา extreme point อย่างไร',\n",
       "  'วิธีการ move adjacent bfs',\n",
       "  'ความแตกต่างระหว่าง degenerate และ nondegenerate',\n",
       "  '_ตัวอย่างการคำนวณ two phase']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_query_map_df = pd.read_csv(\"./data/labeled/file_query_map.csv\")\n",
    "query_dict = dict()\n",
    "for file in os.listdir(f\"./data/labeled\"):\n",
    "    if \"transcript\" not in file:\n",
    "        continue\n",
    "    filename = f\"./data/labeled/{file}\"\n",
    "    file_id = get_id_from_file(filename)\n",
    "    query_dict[file_id] = list()\n",
    "\n",
    "    for query in file_query_map_df.loc[\n",
    "        file_query_map_df.file == file, \"query\"\n",
    "    ].tolist():\n",
    "        query_dict[file_id].append(query)\n",
    "\n",
    "query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "search_time = []\n",
    "for id, query in query_dict.items():\n",
    "    query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "    query = {\n",
    "            \"knn\": {\n",
    "                \"field\": \"embeddings\",\n",
    "                \"query_vector\": query_embedding,\n",
    "                \"num_candidates\": 20,\n",
    "                \"filter\": {\n",
    "                    \"term\" : { \"clip_id\" : id }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    start_time = time.time()\n",
    "    resp = client.search(index=\"transcripts\",size=10, query=query)\n",
    "    end_time = time.time()\n",
    "    search_time.append(end_time - start_time)\n",
    "    # for hit in resp['hits']['hits']:\n",
    "    #     print(hit[\"_source\"][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
